{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "Analyze sample tweets and save in sqLite databases"
            ],
            "metadata": {
                "azdata_cell_guid": "a9232bfc-8b11-47b3-9628-d7d21aed9c54"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "#import necessary modules\n",
                "import sqlite3 \n",
                "import numpy as np \n",
                "import pandas as pd \n",
                "import string \n",
                "import re \n",
                "import nltk\n",
                "nltk.download(\"stopwords\")\n",
                "nltk.download('punkt')\n",
                "nltk.download('averaged_perceptron_tagger')\n",
                "nltk.download('wordnet')\n",
                "from nltk.stem import WordNetLemmatizer\n",
                "from nltk.corpus import wordnet\n",
                "import sklearn"
            ],
            "metadata": {
                "azdata_cell_guid": "65c9f5df-412e-4448-87ba-a345f7ae9b20"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/karengrundy/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     /Users/karengrundy/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /Users/karengrundy/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /Users/karengrundy/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "code",
            "source": [
                "#create the database if it doesn't exist\n",
                "conn = sqlite3.connect('tweets.db') \n",
                "c = conn.cursor()\n",
                "\n",
                "listOfTables = ['jimmyfallon', 'StephenAtHome']"
            ],
            "metadata": {
                "azdata_cell_guid": "966fa425-e8fb-4f6b-a090-db35b4b766a1"
            },
            "outputs": [],
            "execution_count": 4
        },
        {
            "cell_type": "code",
            "source": [
                "def table_exists(table_name): \n",
                "    c.execute('''SELECT count(name) FROM sqlite_master WHERE TYPE = 'table' AND name = '{}' '''.format(table_name)) \n",
                "    if c.fetchone()[0] == 1: \n",
                "        return True \n",
                "    return False\n",
                "\n",
                "def create_tables(table_name):\n",
                "    if not table_exists(table_name): \n",
                "        c.execute(''' \n",
                "            CREATE TABLE {}( \n",
                "                created_at BLOB, \n",
                "                text TEXT, \n",
                "                url TEXT, \n",
                "                replies INT, \n",
                "                retweets INT,\n",
                "                favorites INT,\n",
                "                user TEXT,\n",
                "                whichFile TEXT \n",
                "            ) \n",
                "        '''.format(table_name))\n",
                "\n",
                "def get_tweets(table_name, top_n): \n",
                "    if table_exists(table_name):\n",
                "        if top_n > 0:\n",
                "            c.execute(\"SELECT * FROM {} LIMIT {}\".format(table_name, top_n)) \n",
                "        else:\n",
                "            c.execute(\"SELECT * FROM {}\".format(table_name)) \n",
                "        data = [] \n",
                "        for row in c.fetchall(): \n",
                "            data.append(row) \n",
                "        return data\n",
                "    else:\n",
                "        return \"Table {} does not exist.\".format(table_name)\n",
                "\n",
                "#insert tweets into the jimmyfallon table\n",
                "def insert_tweet(table_name, created_at, text, url, replies, retweets, favorites, user, whichFile): \n",
                "    c.execute(''' INSERT INTO {} (created_at, text, url, replies, retweets, favorites, user, whichFile) VALUES(?, ?, ?, ?, ?, ?, ?, ?) '''.format(table_name), (created_at, text, url, replies, retweets, favorites, user, whichFile)) \n",
                "    conn.commit()\n",
                "\n",
                "def delete_tweets(table_name):\n",
                "    if table_exists(table_name):\n",
                "        c.execute('''DELETE FROM {}'''.format(table_name))\n",
                "    else:\n",
                "        return \"Table {} does not exist.\".format(table_name)\n",
                "\n",
                "def delete_table(table_name):\n",
                "    c.execute('''DROP TABLE IF EXISTS {}'''.format(table_name))\n",
                "\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "01fe2740-838d-4034-91e7-b4a4706abab5"
            },
            "outputs": [],
            "execution_count": 10
        },
        {
            "cell_type": "code",
            "source": [
                "#Import the files, add a column for the file name and add to table in the sqLite database\n",
                "#import the two csv files into a data frames\n",
                "dfJimmyFallonTweets = pd.read_csv(\"jimmyfallon.csv\", encoding=\"ISO-8859-1\")\n",
                "dfStephenAtHomeTweets = pd.read_csv(\"StephenAtHome.csv\", encoding=\"ISO-8859-1\")\n",
                "\n",
                "dfJimmyFallonTweets['whichFile'] = 'jimmyfallon.csv'\n",
                "dfStephenAtHomeTweets['whichFile'] = 'StephenAtHome.csv'"
            ],
            "metadata": {
                "azdata_cell_guid": "1b9857e5-3fea-4e74-8057-bcb1ec16d8de"
            },
            "outputs": [],
            "execution_count": 11
        },
        {
            "cell_type": "code",
            "source": [
                "#delete the tweets if they exist\n",
                "delete_table('jimmyfallon')\n",
                "delete_table('StephenAtHome')\n",
                "delete_table('tweets')"
            ],
            "metadata": {
                "azdata_cell_guid": "b5fbcf2f-0f10-4dd1-a87e-375a9976e06b"
            },
            "outputs": [],
            "execution_count": 12
        },
        {
            "cell_type": "code",
            "source": [
                "#add the tables \n",
                "create_tables('tweets')\n",
                "for index, row in dfJimmyFallonTweets.iterrows():\n",
                "    insert_tweet('tweets',row['created_at'], row['text'], row['url'], row['replies'], row['retweets'], row['favorites'], row['user'], row['whichFile'])\n",
                "\n",
                "for index, row in dfStephenAtHomeTweets.iterrows():\n",
                "    insert_tweet('tweets', row['created_at'], row['text'], row['url'], row['replies'], row['retweets'], row['favorites'], row['user'], row['whichFile'])\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "744e6cc6-5e62-4c9e-881b-a101a953cacc",
                "tags": []
            },
            "outputs": [],
            "execution_count": 13
        },
        {
            "cell_type": "code",
            "source": [
                "#create a dataframe of the combined set of tweets\n",
                "dfWithTweets = pd.DataFrame(get_tweets('tweets', 0), columns=['created_at', 'text', 'url', 'replies', 'retweets', 'favorites', 'user', 'whichFile'])"
            ],
            "metadata": {
                "azdata_cell_guid": "00c4561e-5308-40f5-b780-91f495642d46",
                "tags": []
            },
            "outputs": [],
            "execution_count": 18
        },
        {
            "cell_type": "code",
            "source": [
                "#create a function to clean the data in tweet text\n",
                "def returnCleanedData(data):\n",
                "    \"\"\"user regular expressions to remove all html tags from string data passed to this function and return the cleaned data\"\"\"\n",
                "    data = str(data) #convert the data to a string\n",
                "    dataThatHasBeenCleaned = re.sub(\"<.*?>\",\"\", data)\n",
                "    return dataThatHasBeenCleaned"
            ],
            "metadata": {
                "azdata_cell_guid": "ffe1a742-70e9-4f3d-876a-82f0630071cd"
            },
            "outputs": [],
            "execution_count": 16
        },
        {
            "cell_type": "code",
            "source": [
                "#clean the data in the combined dataframe \n",
                "dfWithTweets[\"text\"] = dfWithTweets[\"text\"].apply(returnCleanedData)"
            ],
            "metadata": {
                "azdata_cell_guid": "de63e10c-6608-4f25-b51a-26459a91cac3"
            },
            "outputs": [],
            "execution_count": 22
        },
        {
            "cell_type": "code",
            "source": [
                "#Read the positive and negative sets\n",
                "with open(\"positive.txt\", \"r\") as myFile:\n",
                "    listOfPositiveWords = myFile.read().split(\"\\n\")\n",
                "\n",
                "with open(\"negative.txt\", \"r\") as myFile:\n",
                "    listOfNegativeWords = myFile.read().split(\"\\n\")"
            ],
            "metadata": {
                "azdata_cell_guid": "f997dc2d-14eb-4031-a63e-693fde7342b2"
            },
            "outputs": [],
            "execution_count": 24
        },
        {
            "cell_type": "code",
            "source": [
                "# create a list that will keep track of the calculated score for each tweet\n",
                "listWithOverallScore = []\n",
                "\n",
                "#Loop through each tweet and clean the text in the \"text\" field\n",
                "for index, row in dfWithTweets.iterrows():\n",
                "    # reset the counter to 0, otherwise, your numbers would reflect the prior iteration of the loop\n",
                "    positiveCounter = 0\n",
                "    negativeCounter = 0\n",
                "\n",
                "    eachTweet = row[\"text\"]\n",
                "\n",
                "    # Begin cleaning the data\n",
                "    # start by making it lowercase - notice we are creating a new variable to store the cleaned data in\n",
                "    eachTweetCleaned = eachTweet.lower()\n",
                "\n",
                "    # remove punctuation\n",
                "    eachTweetCleaned = eachTweetCleaned.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
                "\n",
                "    # remove all whitespace characters (space, tab, newline, return, formfeed, etc.)\n",
                "    eachTweetCleaned = \" \".join(eachTweetCleaned.split())\n",
                "\n",
                "    # just in case, remove extra grouped spaces\n",
                "    eachTweetCleaned = re.sub(\"\\s\\s+\", \" \", eachTweetCleaned)\n",
                "\n",
                "    # split eachTweetCleaned up into a list of words to look at each word and increment the appropriate counter        \n",
                "    listOfWords = eachTweetCleaned.split(\" \")\n",
                "    for eachWord in listOfWords:\n",
                "        if eachWord in listOfPositiveWords:\n",
                "            positiveCounter = positiveCounter + 1\n",
                "        elif eachWord in listOfNegativeWords:\n",
                "            negativeCounter = negativeCounter + 1\n",
                "\n",
                "    # keep track of the item's score in the list listWithOverallScore list variable since we will add that back into the dataframe outside the loop\n",
                "    listWithOverallScore.append(positiveCounter-negativeCounter)\n",
                "\n",
                "dfWithTweets['score'] = listWithOverallScore    \n",
                "    "
            ],
            "metadata": {
                "azdata_cell_guid": "7459a196-a7a1-4486-8f5f-355a95024d34"
            },
            "outputs": [],
            "execution_count": 26
        },
        {
            "cell_type": "code",
            "source": [
                "#Create a table in the database to store the dataframe with scores\n",
                "if not table_exists('sentimentScore'): \n",
                "    c.execute(''' \n",
                "        CREATE TABLE {}( \n",
                "            created_at BLOB, \n",
                "            text TEXT, \n",
                "            url TEXT, \n",
                "            replies INT, \n",
                "            retweets INT,\n",
                "            favorites INT,\n",
                "            user TEXT,\n",
                "            whichFile TEXT,\n",
                "            score INT \n",
                "        ) \n",
                "    '''.format('sentimentScore'))"
            ],
            "metadata": {
                "azdata_cell_guid": "9e169c86-66ae-435b-b700-d33aa016b897"
            },
            "outputs": [],
            "execution_count": 28
        },
        {
            "cell_type": "code",
            "source": [
                "def insert_tweet(created_at, text, url, replies, retweets, favorites, user, whichFile, score): \n",
                "    c.execute(''' INSERT INTO {} (created_at, text, url, replies, retweets, favorites, user, whichFile, score) VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?) '''.format('sentimentScore'), (created_at, text, url, replies, retweets, favorites, user, whichFile, score)) \n",
                "    conn.commit()\n",
                "\n",
                "for index, row in dfWithTweets.iterrows():\n",
                "    insert_tweet(row['created_at'], row['text'], row['url'], row['replies'], row['retweets'], row['favorites'], row['user'], row['whichFile'], row['score'])"
            ],
            "metadata": {
                "azdata_cell_guid": "c80cd21b-864a-4d57-a9bb-a752b55e6952"
            },
            "outputs": [],
            "execution_count": 34
        },
        {
            "cell_type": "code",
            "source": [
                "c.execute(\"SELECT * FROM {} LIMIT {}\".format('sentimentScore', 5)) \n",
                "data = [] \n",
                "for row in c.fetchall(): \n",
                "    data.append(row) \n",
                "\n",
                "pd.DataFrame(data).head()\n",
                "\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "68680bea-5813-4967-90c8-696a460b29f2"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "                  0                                                  1  \\\n0   10/30/2019 1:43  Hit the woah. See you at the movies. This next...   \n1  10/28/2019 22:42                     @GameXplain @Nintendo Not bad.   \n2  10/27/2019 22:51  Playing Ring Fit Adventure on @Nintendo switch...   \n3  10/27/2019 22:37  Speaking of (his movie) #PlayingWithFire! @Joh...   \n4  10/27/2019 14:05  Weve got a brand new #FallonTonight show TONI...   \n\n                                                   2      3     4      5  \\\n0  <a href=\"http://twitter.com/download/iphone\" r...   1360    85   1687   \n1  <a href=\"http://twitter.com/download/iphone\" r...    360    36    881   \n2  <a href=\"http://twitter.com/download/iphone\" r...  12501  1389  15594   \n3  <a href=\"http://twitter.com/download/iphone\" r...   1080    90   1174   \n4  <a href=\"http://twitter.com/download/iphone\" r...   1672    88    922   \n\n             6                7  8  \n0  jimmyfallon  jimmyfallon.csv  1  \n1  jimmyfallon  jimmyfallon.csv -1  \n2  jimmyfallon  jimmyfallon.csv  2  \n3  jimmyfallon  jimmyfallon.csv  1  \n4  jimmyfallon  jimmyfallon.csv -1  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10/30/2019 1:43</td>\n      <td>Hit the woah. See you at the movies. This next...</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n      <td>1360</td>\n      <td>85</td>\n      <td>1687</td>\n      <td>jimmyfallon</td>\n      <td>jimmyfallon.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10/28/2019 22:42</td>\n      <td>@GameXplain @Nintendo Not bad.</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n      <td>360</td>\n      <td>36</td>\n      <td>881</td>\n      <td>jimmyfallon</td>\n      <td>jimmyfallon.csv</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10/27/2019 22:51</td>\n      <td>Playing Ring Fit Adventure on @Nintendo switch...</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n      <td>12501</td>\n      <td>1389</td>\n      <td>15594</td>\n      <td>jimmyfallon</td>\n      <td>jimmyfallon.csv</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10/27/2019 22:37</td>\n      <td>Speaking of (his movie) #PlayingWithFire! @Joh...</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n      <td>1080</td>\n      <td>90</td>\n      <td>1174</td>\n      <td>jimmyfallon</td>\n      <td>jimmyfallon.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10/27/2019 14:05</td>\n      <td>Weve got a brand new #FallonTonight show TONI...</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n      <td>1672</td>\n      <td>88</td>\n      <td>922</td>\n      <td>jimmyfallon</td>\n      <td>jimmyfallon.csv</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {},
                    "execution_count": 36,
                    "output_type": "execute_result"
                }
            ],
            "execution_count": 36
        },
        {
            "cell_type": "code",
            "source": [
                "#close the cursor\n",
                "c.close()\n",
                "\n",
                "# and close the connection to the database\n",
                "try:\n",
                "    conn.close()\n",
                "    print(\"connection closed\")\n",
                "except:\n",
                "    print(\"connection already closed\")"
            ],
            "metadata": {
                "azdata_cell_guid": "2e95bfbf-c565-4ce1-9365-cdde1057e1c0"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "connection closed\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 37
        }
    ]
}